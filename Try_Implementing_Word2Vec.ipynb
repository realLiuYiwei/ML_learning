{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOGvAMTrT1nNWTuDk6dJpkM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/realLiuYiwei/ML_learning/blob/main/Try_Implementing_Word2Vec.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5Cq39k5uPR2A"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow.compat.v1 as tf\n",
        "corpus_raw = 'He is the king . The king is royal . She is the royal  queen '\n",
        "# convert to lower case\n",
        "corpus_raw = corpus_raw.lower()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "words = []\n",
        "for word in corpus_raw.split():\n",
        "    if word != '.': # because we don't want to treat . as a word\n",
        "        words.append(word)\n",
        "words = set(words) # so that all duplicate words are removed\n",
        "word2int = {}\n",
        "int2word = {}\n",
        "vocab_size = len(words) # gives the total number of unique words\n",
        "for i,word in enumerate(words):\n",
        "    word2int[word] = i\n",
        "    int2word[i] = word"
      ],
      "metadata": {
        "id": "eoTC4wYdPkVS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(word2int)\n",
        "print(int2word)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ffFI33oPej8Z",
        "outputId": "58031e13-aaaf-4b49-b899-2e6533f8565a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'king': 0, 'he': 1, 'the': 2, 'queen': 3, 'she': 4, 'royal': 5, 'is': 6}\n",
            "{0: 'king', 1: 'he', 2: 'the', 3: 'queen', 4: 'she', 5: 'royal', 6: 'is'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# raw sentences is a list of sentences.\n",
        "raw_sentences = corpus_raw.split('.')\n",
        "sentences = []\n",
        "for sentence in raw_sentences:\n",
        "    sentences.append(sentence.split())"
      ],
      "metadata": {
        "id": "W4TdHhtFPsNI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(sentences)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6b-kSinfPuse",
        "outputId": "3e9b3b25-d662-4d92-ac64-a595956cbd3a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['he', 'is', 'the', 'king'], ['the', 'king', 'is', 'royal'], ['she', 'is', 'the', 'royal', 'queen']]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = []\n",
        "WINDOW_SIZE = 2\n",
        "for sentence in sentences:\n",
        "    for word_index, word in enumerate(sentence):\n",
        "        for nb_word in sentence[max(word_index - WINDOW_SIZE, 0) : min(word_index + WINDOW_SIZE, len(sentence)) + 1]: \n",
        "            if nb_word != word:\n",
        "                data.append([word, nb_word])"
      ],
      "metadata": {
        "id": "sfWlhg_qP6LC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UMtlQWDFey3D",
        "outputId": "501df467-5668-40fa-aa5e-a45f45974ae1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['he', 'is'], ['he', 'the'], ['is', 'he'], ['is', 'the'], ['is', 'king'], ['the', 'he'], ['the', 'is'], ['the', 'king'], ['king', 'is'], ['king', 'the'], ['the', 'king'], ['the', 'is'], ['king', 'the'], ['king', 'is'], ['king', 'royal'], ['is', 'the'], ['is', 'king'], ['is', 'royal'], ['royal', 'king'], ['royal', 'is'], ['she', 'is'], ['she', 'the'], ['is', 'she'], ['is', 'the'], ['is', 'royal'], ['the', 'she'], ['the', 'is'], ['the', 'royal'], ['the', 'queen'], ['royal', 'is'], ['royal', 'the'], ['royal', 'queen'], ['queen', 'the'], ['queen', 'royal']]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zbeca02rtukI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# function to convert numbers to one hot vectors\n",
        "def to_one_hot(data_point_index, vocab_size):\n",
        "    temp = np.zeros(vocab_size)\n",
        "    temp[data_point_index] = 1\n",
        "    return temp\n",
        "x_train = [] # input word\n",
        "y_train = [] # output word\n",
        "for data_word in data:\n",
        "    x_train.append(to_one_hot(word2int[ data_word[0] ], vocab_size))\n",
        "    y_train.append(to_one_hot(word2int[ data_word[1] ], vocab_size))\n",
        "# convert them to numpy arrays\n",
        "x_train = np.asarray(x_train)\n",
        "y_train = np.asarray(y_train)"
      ],
      "metadata": {
        "id": "7Yes-XTRP_Qf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Making the tensorflow model"
      ],
      "metadata": {
        "id": "j5UEC60uiahg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# making placeholders for x_train and y_train\n",
        "tf.compat.v1.disable_eager_execution()\n",
        "x = tf.placeholder(tf.float32, shape=(None, vocab_size))\n",
        "y_label = tf.placeholder(tf.float32, shape=(None, vocab_size))"
      ],
      "metadata": {
        "id": "yTRVG7jOfnlc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We take our training data and convert into the embedded representation"
      ],
      "metadata": {
        "id": "9DW9ypBuiWvB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "EMBEDDING_DIM = 5\n",
        "W1 = tf.Variable(tf.random_normal([vocab_size, EMBEDDING_DIM]))\n",
        "b1 = tf.Variable(tf.random_normal([EMBEDDING_DIM]))     #bias\n",
        "hidden_representation = tf.add(tf.matmul(x,W1), b1)"
      ],
      "metadata": {
        "id": "YeyR4BlvhjYv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, we take what we have in the embedded dimension and make a prediction about the neighbour. To make the prediction we use softmax"
      ],
      "metadata": {
        "id": "TjlBVC3Siyex"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(hidden_representation)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3J_I6MkWiTiu",
        "outputId": "ae046373-92c7-43fe-f04a-6eeb161d21d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tensor(\"Add_12:0\", shape=(None, 5), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "W2 = tf.Variable(tf.random_normal([EMBEDDING_DIM, vocab_size]))\n",
        "b2 = tf.Variable(tf.random_normal([vocab_size]))\n",
        "\n",
        "prediction = tf.nn.softmax(tf.add(tf.matmul(hidden_representation, W2), b2))"
      ],
      "metadata": {
        "id": "leNHI6hwllmw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sess = tf.Session()\n",
        "init = tf.global_variables_initializer()\n",
        "\n",
        "sess.run(init) # must do this\n",
        "\n",
        "# define the loss function:\n",
        "cross_entropy_loss = tf.reduce_mean(-tf.reduce_sum(y_label * tf.log(prediction), reduction_indices=[1]))\n",
        "\n",
        "#define the training step:\n",
        "train_step = tf.train.GradientDescentOptimizer(0.1).minimize(cross_entropy_loss)\n",
        "\n",
        "n_iters = 10000\n",
        "\n",
        "#train for n_iter iterations\n",
        "\n",
        "for _ in range(n_iters):\n",
        "  sess.run(train_step, feed_dict={x: x_train, y_label: y_train})\n"
      ],
      "metadata": {
        "id": "WH06zZf-n96M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(sess.run(W1))\n",
        "print('----------')\n",
        "print(sess.run(b1))\n",
        "print('----------')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zNfjCJclp79W",
        "outputId": "f0c0dc75-d379-4092-f9c0-35b398275c1f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[-2.1272097   0.3586792  -0.9803731   0.2708516  -0.6239545 ]\n",
            " [-0.5522463   0.6938541  -0.24835221 -0.5188872  -1.5383853 ]\n",
            " [ 1.9780777  -0.90808475 -1.092655   -0.04184348  1.1801578 ]\n",
            " [-2.2413158   0.86413836  0.3117944  -1.443656    2.0441027 ]\n",
            " [ 0.3510447  -0.55387187 -0.772945   -0.7994312  -0.80496186]\n",
            " [-0.46319884 -0.46611163 -1.3791208   2.6543853  -0.5446122 ]\n",
            " [-0.36220688 -2.0924256   0.38797283  1.1197618   2.7599006 ]]\n",
            "----------\n",
            "[ 0.20014861  0.50772685 -1.2425529  -0.8216071  -0.52395654]\n",
            "----------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vectors = sess.run(W1 + b1)\n",
        "\n",
        "# if you work it out, you will see that it has the same effect as running the node hidden representation\n",
        "print(vectors)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ILdjylDqQyQ",
        "outputId": "74450090-55c2-4eba-ef61-6bd9561c8b81"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[-1.9270611   0.8664061  -2.222926   -0.5507555  -1.1479111 ]\n",
            " [-0.35209766  1.201581   -1.490905   -1.3404944  -2.0623417 ]\n",
            " [ 2.1782262  -0.4003579  -2.335208   -0.8634506   0.65620124]\n",
            " [-2.0411673   1.3718653  -0.9307585  -2.265263    1.5201461 ]\n",
            " [ 0.55119336 -0.04614502 -2.015498   -1.6210383  -1.3289185 ]\n",
            " [-0.26305023  0.04161522 -2.6216736   1.8327782  -1.0685687 ]\n",
            " [-0.16205826 -1.5846987  -0.85458004  0.2981547   2.235944  ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(vectors[ word2int['queen'] ])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AHpaPAEDqUoA",
        "outputId": "f70e6713-a040-4f52-d48e-069c5b1a7997"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[-2.0411673  1.3718653 -0.9307585 -2.265263   1.5201461]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def euclidean_dist(vec1, vec2):\n",
        "    return np.sqrt(np.sum((vec1-vec2)**2))\n",
        "def find_closest(word_index, vectors):\n",
        "    min_dist = 10000 # to act like positive infinity\n",
        "    min_index = -1\n",
        "    query_vector = vectors[word_index]\n",
        "    for index, vector in enumerate(vectors):\n",
        "        if euclidean_dist(vector, query_vector) < min_dist and not np.array_equal(vector, query_vector):\n",
        "            min_dist = euclidean_dist(vector, query_vector)\n",
        "            min_index = index\n",
        "    return min_index"
      ],
      "metadata": {
        "id": "bPIIenduqbbH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(int2word[find_closest(word2int['king'], vectors)])\n",
        "print(int2word[find_closest(word2int['queen'], vectors)])\n",
        "print(int2word[find_closest(word2int['royal'], vectors)])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x_hNkCUJqe1E",
        "outputId": "78149e5b-23c7-4b7f-893d-d0b7a7dfe047"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "he\n",
            "king\n",
            "king\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.manifold import TSNE\n",
        "model = TSNE(n_components=2, random_state=0)\n",
        "np.set_printoptions(suppress=True)\n",
        "vectors = model.fit_transform(vectors)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s6a7tFDqh2T-",
        "outputId": "439a7267-073f-48ce-9568-bab9e94968c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/manifold/_t_sne.py:780: FutureWarning: The default initialization in TSNE will change from 'random' to 'pca' in 1.2.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/manifold/_t_sne.py:790: FutureWarning: The default learning rate in TSNE will change from 200.0 to 'auto' in 1.2.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import preprocessing\n",
        "normalizer = preprocessing.Normalizer()\n",
        "vectors = normalizer.fit_transform(vectors,'l2')"
      ],
      "metadata": {
        "id": "0DBcfV5ajLkH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "fig, ax = plt.subplots()\n",
        "for word in words:\n",
        "    print(word, vectors[word2int[word]][1])\n",
        "    ax.annotate(word, (vectors[word2int[word]][0],vectors[word2int[word]][1] ))\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 577
        },
        "id": "SedmuzExjl57",
        "outputId": "761e3e66-969c-49b1-b9fd-336b1a87a29e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "king 0.89717036\n",
            "he 0.25030422\n",
            "the 0.9601968\n",
            "queen 0.50680053\n",
            "she -0.9047838\n",
            "royal 0.9838481\n",
            "is -0.40288413\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}